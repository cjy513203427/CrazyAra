{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training script for the CNN \n",
    "\n",
    "Loads in the converted plane representation of the pgn files, defines the network architecture and starts the training process. Checkpoints of the weights are saved if there's an improvement in the validation loss.\n",
    "The training performance metrics (e.g. losses, accuracies...) are exported to tensorboard and can be checked during training.\n",
    "* author: QueensGambit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 18:06:15 matplotlib.pyplot[12628] \u001b[1mDEBUG\u001b[0m Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "2023-07-17 18:06:15 matplotlib.pyplot[12628] \u001b[1mDEBUG\u001b[0m Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'../../../')\n",
    "import glob\n",
    "import chess\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "from DeepCrazyhouse.src.training.train_util import get_metrics, prepare_policy, value_to_wdl_label, prepare_plys_label\n",
    "from DeepCrazyhouse.src.domain.variants.input_representation import board_to_planes, planes_to_board\n",
    "from DeepCrazyhouse.src.domain.variants.output_representation import policy_to_moves, policy_to_best_move, policy_to_move\n",
    "from DeepCrazyhouse.src.preprocessing.dataset_loader import load_pgn_dataset\n",
    "from DeepCrazyhouse.src.runtime.color_logger import enable_color_logging\n",
    "from DeepCrazyhouse.configs.main_config import main_config\n",
    "from DeepCrazyhouse.configs.train_config import TrainConfig, TrainObjects\n",
    "\n",
    "from DeepCrazyhouse.src.training.lr_schedules.lr_schedules import *\n",
    "from DeepCrazyhouse.src.domain.variants.plane_policy_representation import FLAT_PLANE_IDX\n",
    "from DeepCrazyhouse.src.domain.variants.constants import NB_POLICY_MAP_CHANNELS, NB_LABELS, MODE_CHESS, MODE_CRAZYHOUSE\n",
    "enable_color_logging()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TrainConfig()\n",
    "to = TrainObjects()\n",
    "# Decide between 'pytorch', 'mxnet' and 'gluon' style for training\n",
    "tc.framework: str = 'pytorch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tc.framework == 'pytorch':\n",
    "    import torch\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    from torchsummary import summary\n",
    "    from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "    from DeepCrazyhouse.src.training.trainer_agent_pytorch import TrainerAgentPytorch, save_torch_state,\\\n",
    "    load_torch_state, export_to_onnx, get_context, get_data_loader, evaluate_metrics\n",
    "    # architectures\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.pytorch.rise_mobile_v3 import RiseV3, get_rise_v33_model_by_train_config\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.pytorch.vision_transformer import VisionTransformer\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.pytorch.vit_configs import get_b8_config\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.pytorch.le_vit import LeViT\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.pytorch.mobile_vit import MobileViT\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.pytorch.trt_vit import TrtViT\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.pytorch.next_vit_official import NextVit\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.pytorch.a0_resnet import AlphaZeroResnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mxnet imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tc.framework == 'mxnet' or tc.framework == 'gluon':\n",
    "    import mxnet as mx\n",
    "    from mxnet import nd\n",
    "    from mxnet import gluon\n",
    "    try:\n",
    "        import mxnet.metric as metric\n",
    "    except ModuleNotFoundError:\n",
    "        import mxnet.gluon.metric as metrics\n",
    "\n",
    "    from DeepCrazyhouse.src.training.trainer_agent_gluon import TrainerAgentGluon, evaluate_metrics, acc_sign, get_data_loader\n",
    "    from DeepCrazyhouse.src.training.trainer_agent_mxnet import TrainerAgentMXNET, get_context\n",
    "    # architectures\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.a0_resnet import AlphaZeroResnet\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.mxnet_alpha_zero import alpha_zero_symbol\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.rise_mobile_v2 import rise_mobile_v2_symbol\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.rise_mobile_v3 import rise_mobile_v3_symbol\n",
    "    from DeepCrazyhouse.src.domain.neural_net.architectures.preact_resnet_se import preact_resnet_se\n",
    "    from DeepCrazyhouse.src.domain.neural_net.onnx.convert_to_onnx import convert_mxnet_model_to_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the context on CPU, switch to GPU if there is one available (strongly recommended for training)\n",
    "tc.context = \"gpu\"\n",
    "tc.device_id = 0\n",
    "\n",
    "# set a specific seed value for reproducibility\n",
    "tc.seed = 7 # 42\n",
    "\n",
    "tc.export_weights = True\n",
    "tc.log_metrics_to_tensorboard = True\n",
    "tc.export_grad_histograms = False\n",
    "\n",
    "# directory to write and read weights, logs, onnx and other export files\n",
    "tc.export_dir = \"./\"\n",
    "\n",
    "tc.div_factor = 4  # div factor is a constant which can be used to reduce the batch size and learning rate respectively\n",
    "# use a value greater 1 if you encounter memory allocation errors\n",
    "\n",
    "# batch_steps = 1000 means for example that every 1000 batches the validation set gets processed\n",
    "tc.batch_steps = 1000 * tc.div_factor # this defines how often a new checkpoint will be saved and the metrics evaluated\n",
    "# k_steps_initial defines how many steps have been trained before\n",
    "# (k_steps_initial != 0 if you continue training from a checkpoint)\n",
    "tc.k_steps_initial = 0\n",
    "# these are the weights to continue training with\n",
    "tc.symbol_file = None # 'model-0.81901-0.713-symbol.json'\n",
    "tc.params_file = None #'model-0.81901-0.713-0498.params'\n",
    "\n",
    "tc.batch_size = int(1024 / tc.div_factor) # 1024 # the batch_size needed to be reduced to 1024 in order to fit in the GPU 1080Ti\n",
    "#4096 was originally used in the paper -> works slower for current GPU\n",
    "# 2048 was used in the paper Mastering the game of Go without human knowledge and fits in GPU memory\n",
    "#typically if you half the batch_size, you should double the lr\n",
    "\n",
    "# optimization parameters\n",
    "tc.optimizer_name = \"nag\"  # \"adam\" \"adamw\" # \n",
    "if tc.framework == 'pytorch':\n",
    "    # strangely pytorch should use a different lr than mxnet\n",
    "    tc.max_lr = 0.07 / tc.div_factor\n",
    "else:\n",
    "    tc.max_lr = 0.35 / tc.div_factor #0.01 # default lr for adam\n",
    "tc.min_lr = 0.00001\n",
    "\n",
    "if \"adam\" in tc.optimizer_name:\n",
    "    tc.max_lr = 0.001001 #1e-3\n",
    "    tc.min_lr = 0.001\n",
    "    \n",
    "tc.max_momentum = 0.95\n",
    "tc.min_momentum = 0.8\n",
    "# loads a previous checkpoint if the loss increased significanly\n",
    "tc.use_spike_recovery = True\n",
    "# stop training as soon as max_spikes has been reached\n",
    "tc.max_spikes = 20\n",
    "# define spike threshold when the detection will be triggered\n",
    "tc.spike_thresh = 1.5\n",
    "# weight decay\n",
    "tc.wd = 1e-4\n",
    "tc.dropout_rate = 0 #0.15\n",
    "\n",
    "# enables training with a wdl head as intermediate target (mainly useful for environments with 3 outcomes)\n",
    "tc.use_wdl = True\n",
    "# enables training with ply to end head\n",
    "tc.use_plys_to_end = True\n",
    "# adds a small mlp to infer the value loss from wdl and plys_to_end_output\n",
    "tc.use_mlp_wdl_ply = False\n",
    "\n",
    "# weight the value loss a lot lower than the policy loss in order to prevent overfitting\n",
    "tc.val_loss_factor = 0.01\n",
    "tc.policy_loss_factor = 0.988 if tc.use_plys_to_end else 0.99\n",
    "tc.plys_to_end_loss_factor = 0.002\n",
    "tc.wdl_loss_factor = 0.01\n",
    "tc.discount = 1.0\n",
    "\n",
    "tc.normalize = True # define whether to normalize input data to [0,1]\n",
    "tc.nb_training_epochs = 7 # define how many epochs the network will be trained\n",
    "tc.select_policy_from_plane = True # Boolean if potential legal moves will be selected from final policy output\n",
    "        \n",
    "# additional custom validation set files which will be logged to tensorboard\n",
    "to.variant_metrics = None # [\"chess960\", \"koth\", \"three_check\"]\n",
    "# if use_extra_variant_input is true the current active variant is passed two each residual block and\n",
    "\n",
    "# ratio for mixing the value return with the corresponding q-value\n",
    "# for a ratio of 0 no q-value information will be used\n",
    "tc.q_value_ratio = 0\n",
    "\n",
    "# define if policy training target is one-hot encoded a distribution (e.g. mcts samples, knowledge distillation)\n",
    "tc.sparse_policy_label = True\n",
    "# define if the policy data is also defined in \"select_policy_from_plane\" representation\n",
    "tc.is_policy_from_plane_data = False\n",
    "tc.name_initials = \"JC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = main_config[\"mode\"]\n",
    "ctx = get_context(tc.context, tc.device_id)\n",
    "# concatenated at the end of the final feature representation\n",
    "use_extra_variant_input = False\n",
    "cur_it = tc.k_steps_initial * tc.batch_steps # iteration counter used for the momentum and learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if tc.framework == 'mxnet' or tc.framework == 'gluon':\n",
    "    # Fixing the random seed\n",
    "    mx.random.seed(tc.seed)\n",
    "    mx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create logs and weights directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(tc.export_dir + \"logs\"):\n",
    "    os.mkdir(tc.export_dir + \"logs\")\n",
    "if not os.path.exists(tc.export_dir + \"weights\"):\n",
    "    os.mkdir(tc.export_dir + \"weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pgn_train_dir': '/home/demo_user/datasets/lichess/Crazyhouse/pgn/train/', 'pgn_val_dir': '/home/demo_user/datasets/lichess/Crazyhouse/pgn/val/', 'pgn_test_dir': '/home/demo_user/datasets/lichess/Crazyhouse/pgn/test/', 'pgn_mate_in_one_dir': '/home/demo_user/datasets/lichess/Crazyhouse/pgn/mate_in_one/', 'planes_train_dir': 'D:/Jinyao/Masterarbeit/datasets/datasets/24k_dataset/default/planes/train/', 'planes_val_dir': 'D:/Jinyao/Masterarbeit/datasets/datasets/24k_dataset/default/planes/val/', 'planes_test_dir': 'D:/Jinyao/Masterarbeit/datasets/datasets/24k_dataset/default/planes/test/', 'planes_mate_in_one_dir': 'D:/Jinyao/Masterarbeit/datasets/datasets/24k_dataset/default/planes/mate_in_one/', 'rec_dir': '/home/demo_user/datasets/lichess/Crazyhouse/rec/', 'model_architecture_dir': '/home/demo_user/models/Crazyhouse/symbol/', 'model_weights_dir': '/home/demo_user/models/Crazyhouse/params/', 'value_output': 'value_out', 'policy_output': 'policy_out', 'auxiliary_output': 'auxiliary_out', 'wdl_output': 'wdl_out', 'plys_to_end_output': 'plys_to_end_out', 'mode': 0, 'version': 1}\n"
     ]
    }
   ],
   "source": [
    "print(main_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainConfig(div_factor=1, batch_size=1024, batch_steps=1000, context='gpu', cpu_count=4, device_id=0, discount=1.0, dropout_rate=0, export_dir='./', export_weights=True, export_grad_histograms=False, framework='pytorch', is_policy_from_plane_data=False, log_metrics_to_tensorboard=True, k_steps_initial=0, symbol_file=None, params_file=None, optimizer_name='nag', max_lr=0.07, min_lr=1e-05, max_momentum=0.95, min_momentum=0.8, max_spikes=20, name_initials='JC', nb_parts=None, normalize=True, nb_training_epochs=3, policy_loss_factor=0.988, plys_to_end_loss_factor=0.002, q_value_ratio=0, seed=7, select_policy_from_plane=True, spike_thresh=1.5, sparse_policy_label=True, total_it=None, use_mlp_wdl_ply=False, use_plys_to_end=True, use_wdl=True, use_spike_recovery=True, val_loss_factor=0.01, wdl_loss_factor=0.01, wd=0.0001)\n"
     ]
    }
   ],
   "source": [
    "print(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainObjects()\n"
     ]
    }
   ],
   "source": [
    "print(to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataset (which is used during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 18:06:18 root[12628] \u001b[1mDEBUG\u001b[0m loading: D:/Jinyao/Masterarbeit/datasets/datasets/24k_dataset/default/planes/val\\2021-01-12-14-14-24\\lichess_db_crazyhouse_rated_2018-04_0.zip ...\n",
      "2023-07-17 18:06:18 root[12628] \u001b[1mDEBUG\u001b[0m \n",
      "2023-07-17 18:06:19 root[12628] \u001b[1mINFO\u001b[0m STATISTICS:\n",
      "black_wins [444]\n",
      "draws [2]\n",
      "game_idx_end [1000]\n",
      "game_idx_start [0]\n",
      "number_selected_games [1000]\n",
      "white_wins [554]\n",
      "2023-07-17 18:06:19 root[12628] \u001b[1mINFO\u001b[0m PARAMETERS:\n",
      "batch_size [1000]\n",
      "compression [b'lz4']\n",
      "limit_nb_games [0]\n",
      "max_nb_files [1]\n",
      "min_elo_both [2000]\n",
      "pgn_name [b'lichess_db_crazyhouse_rated_2018-04.pgn']\n",
      "termination_conditions [b'Normal']\n"
     ]
    }
   ],
   "source": [
    "s_idcs_val, x_val, yv_val, yp_val, plys_to_end, pgn_datasets_val = load_pgn_dataset(dataset_type='val', part_id=0,\n",
    "                                                                           verbose=True, normalize=tc.normalize)\n",
    "if tc.discount != 1:\n",
    "    yv_val *= tc.discount**plys_to_end\n",
    "    \n",
    "if tc.framework == 'mxnet':\n",
    "    if tc.select_policy_from_plane:\n",
    "        if tc.use_wdl and tc.use_wdl:\n",
    "            val_iter = mx.io.NDArrayIter({'data': x_val},\n",
    "                                         {'value_label': yv_val,\n",
    "                                          'policy_label': np.array(FLAT_PLANE_IDX)[yp_val.argmax(axis=1)],\n",
    "                                          'wdl_label': value_to_wdl_label(yv_val),\n",
    "                                          'plys_to_end_label': prepare_plys_label(plys_to_end)},\n",
    "                                          tc.batch_size)\n",
    "        else:\n",
    "            val_iter = mx.io.NDArrayIter({'data': x_val},\n",
    "                                         {'value_label': yv_val,\n",
    "                                          'policy_label': np.array(FLAT_PLANE_IDX)[yp_val.argmax(axis=1)]},\n",
    "                                         tc.batch_size)\n",
    "    else:\n",
    "        val_iter = mx.io.NDArrayIter({'data': x_val}, {'value_label': yv_val, 'policy_label': yp_val.argmax(axis=1)}, tc.batch_size)\n",
    "elif tc.framework == 'gluon' or tc.framework == 'pytorch':\n",
    "    val_data = get_data_loader(x_val, yv_val, yp_val, plys_to_end, tc, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tc.nb_parts = len(glob.glob(main_config['planes_train_dir'] + '**/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4044"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_it_per_epoch = (len(x_val) * tc.nb_parts) // tc.batch_size # calculate how many iterations per epoch exist\n",
    "# one iteration is defined by passing 1 batch and doing backprop\n",
    "tc.total_it = int(nb_it_per_epoch * tc.nb_training_epochs)\n",
    "tc.total_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Learning Rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if \"adam\" in tc.optimizer_name:\n",
    "    to.lr_schedule = ConstantSchedule(tc.min_lr)\n",
    "else:\n",
    "    to.lr_schedule = OneCycleSchedule(start_lr=tc.max_lr/8, max_lr=tc.max_lr, cycle_length=tc.total_it*.3, cooldown_length=tc.total_it*.6, finish_lr=tc.min_lr)\n",
    "to.lr_schedule = LinearWarmUp(to.lr_schedule, start_lr=tc.min_lr, length=tc.total_it/30)\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "plot_schedule(to.lr_schedule, iterations=tc.total_it)\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to.momentum_schedule = MomentumSchedule(to.lr_schedule, tc.min_lr, tc.max_lr, tc.min_momentum, tc.max_momentum)\n",
    "plot_schedule(to.momentum_schedule, iterations=tc.total_it, ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 8, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x_val[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del net\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the NN model / Load the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MXNet model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbol = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#net = AlphaZeroResnet(n_labels=2272, channels=256, channels_value_head=8, channels_policy_head=81, num_res_blocks=19, value_fc_size=256, bn_mom=0.9, act_type='relu', select_policy_from_plane=select_policy_from_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#net = alpha_zero_resnet(n_labels=2272, channels=256, channels_value_head=1, channels_policy_head=81, num_res_blocks=19, value_fc_size=256, bn_mom=0.9, act_type='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#symbol = alpha_zero_symbol(num_filter=256, channels_value_head=4, channels_policy_head=81, workspace=1024, value_fc_size=256, num_res_blocks=19, bn_mom=0.9, act_type='relu',\n",
    "#                            n_labels=2272, grad_scale_value=0.01, grad_scale_policy=0.99, select_policy_from_plane=select_policy_from_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bc_res_blocks = [3] * 13\n",
    "#if tc.symbol_file is None:\n",
    "#    symbol = rise_mobile_v2_symbol(channels=256, channels_operating_init=128, channel_expansion=64, channels_value_head=8,\n",
    "#                      channels_policy_head=NB_POLICY_MAP_CHANNELS, value_fc_size=256, bc_res_blocks=bc_res_blocks, res_blocks=[], act_type='relu',\n",
    "#                      n_labels=NB_LABELS, grad_scale_value=tc.val_loss_factor, grad_scale_policy=tc.policy_loss_factor, select_policy_from_plane=tc.select_policy_from_plane,\n",
    "#                      use_se=True, dropout_rate=tc.dropout_rate, use_extra_variant_input=use_extra_variant_input)\n",
    "#else:\n",
    "#    symbol = mx.sym.load(tc.export_dir + \"weights/\" + tc.symbol_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernels = [3] * 15\n",
    "kernels[7] = 5\n",
    "kernels[11] = 5\n",
    "kernels[12] = 5\n",
    "kernels[13] = 5\n",
    "\n",
    "se_types = [None] * len(kernels)\n",
    "se_types[5] = \"eca_se\"\n",
    "se_types[8] = \"eca_se\"\n",
    "se_types[12] = \"eca_se\"\n",
    "se_types[13] = \"eca_se\"\n",
    "se_types[14] = \"eca_se\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernels = [3] * 7\n",
    "\n",
    "se_types = [None] * len(kernels)\n",
    "se_types[5] = \"eca_se\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "symbol = rise_mobile_v3_symbol(channels=256, channels_operating_init=224, channel_expansion=32, act_type='relu',\n",
    "                               channels_value_head=8, value_fc_size=256,\n",
    "                               channels_policy_head=NB_POLICY_MAP_CHANNELS,\n",
    "                               grad_scale_value=tc.val_loss_factor,\n",
    "                               grad_scale_policy=tc.policy_loss_factor,\n",
    "                               grad_scale_wdl=tc.wdl_loss_factor,\n",
    "                               grad_scale_ply=tc.plys_to_end_loss_factor,\n",
    "                               dropout_rate=tc.dropout_rate, select_policy_from_plane=True,\n",
    "                               kernels=kernels, se_types=se_types, use_avg_features=False,\n",
    "                               use_wdl=tc.use_wdl, use_plys_to_end=tc.use_plys_to_end,\n",
    "                               use_mlp_wdl_ply=tc.use_mlp_wdl_ply\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernels = [3,3,3,3,3,3,5,5]\n",
    "\n",
    "se_types = [\n",
    "    None, # 1\n",
    "    None, # 2\n",
    "    None,  # 3\n",
    "    \"eca_se\",  # 4\n",
    "    None, # 5\n",
    "    None,  # 6\n",
    "    None, # 7\n",
    "    \"eca_se\", # 8\n",
    "] \n",
    "\n",
    "symbol = preact_resnet_se(channels=288, act_type='relu',\n",
    "                          channels_value_head=8, value_fc_size=256,\n",
    "                          channels_policy_head=NB_POLICY_MAP_CHANNELS,\n",
    "                          grad_scale_value=tc.val_loss_factor, grad_scale_policy=tc.policy_loss_factor, \n",
    "                          dropout_rate=tc.dropout_rate, select_policy_from_plane=True,\n",
    "                          kernels=kernels, se_types=se_types, use_avg_features=True, use_raw_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_rise_v33_model_by_train_config(input_shape, tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = LeViT(\n",
    "    image_size = input_shape[1],\n",
    "    in_channels = input_shape[0],\n",
    "    channels_policy_head = NB_POLICY_MAP_CHANNELS,\n",
    "    stages = 1,             # number of stages\n",
    "    dim = (256,),  # dimensions at each stage\n",
    "    depth = 9,              # transformer of depth 4 at each stage\n",
    "    heads = (4,),      # heads at each stage\n",
    "    mlp_mult = 2,\n",
    "    dropout = 0.1,\n",
    "    select_policy_from_plane=tc.select_policy_from_plane,\n",
    "    use_wdl=tc.use_wdl, use_plys_to_end=tc.use_plys_to_end,\n",
    "    use_mlp_wdl_ply=tc.use_mlp_wdl_ply,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = MobileViT(\n",
    "    image_size = (input_shape[1], input_shape[2]),\n",
    "    in_channels = input_shape[0],\n",
    "    dims = [96, 120, 144],\n",
    "    channels = 256,\n",
    "    channels_policy_head = NB_POLICY_MAP_CHANNELS,\n",
    "    select_policy_from_plane=tc.select_policy_from_plane,\n",
    "    use_wdl=tc.use_wdl, use_plys_to_end=tc.use_plys_to_end,\n",
    "    use_mlp_wdl_ply=tc.use_mlp_wdl_ply,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = TrtViT(\n",
    "    image_size = input_shape[1],\n",
    "    in_channels = input_shape[0],\n",
    "    channels_policy_head = NB_POLICY_MAP_CHANNELS,\n",
    "    channels=256,\n",
    "    select_policy_from_plane=tc.select_policy_from_plane,\n",
    "    use_wdl=tc.use_wdl, use_plys_to_end=tc.use_plys_to_end,\n",
    "    use_mlp_wdl_ply=tc.use_mlp_wdl_ply,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernels = [3] * 12 #15\n",
    "kernels[10] = 5\n",
    "kernels[9] = 5\n",
    "kernels[5] = 5\n",
    "#kernels[13] = 5\n",
    "\n",
    "use_transformers = [False] * len(kernels)\n",
    "use_transformers[11] = True\n",
    "#use_transformers[9] = True\n",
    "#use_transformers[4] = True\n",
    "\n",
    "se_types = [None] * len(kernels)\n",
    "se_types[5] = \"eca_se\"\n",
    "se_types[11] = \"eca_se\"\n",
    "#se_types[12] = \"eca_se\"\n",
    "#se_types[13] = \"eca_se\"\n",
    "#se_types[14] = \"eca_se\"\n",
    "\n",
    "class Args:\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.input_shape = input_shape\n",
    "args.channels_policy_head = NB_POLICY_MAP_CHANNELS\n",
    "args.n_labels = NB_LABELS\n",
    "args.select_policy_from_plane = tc.select_policy_from_plane\n",
    "args.use_wdl = tc.use_wdl\n",
    "args.use_plys_to_end = tc.use_plys_to_end\n",
    "args.use_mlp_wdl_ply = tc.use_mlp_wdl_ply\n",
    "\n",
    "model = RiseV3(nb_input_channels=args.input_shape[0], board_height=args.input_shape[1], board_width=args.input_shape[2],\n",
    "                channels=256, channels_operating_init=224, channel_expansion=32,\n",
    "                channels_value_head=8, value_fc_size=256,\n",
    "                channels_policy_head=args.channels_policy_head,\n",
    "                dropout_rate=0, select_policy_from_plane=args.select_policy_from_plane,\n",
    "                kernels=kernels, se_types=se_types, use_avg_features=False, n_labels=args.n_labels,\n",
    "                use_wdl=args.use_wdl, use_plys_to_end=args.use_plys_to_end, use_mlp_wdl_ply=args.use_mlp_wdl_ply,\n",
    "                use_transformers=use_transformers, path_dropout=0.07\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = NextVit(\n",
    "    image_size = input_shape[1],\n",
    "    in_channels = input_shape[0],\n",
    "    channels_policy_head = NB_POLICY_MAP_CHANNELS,\n",
    "    stage3_repeat=1,\n",
    "    channels=256,\n",
    "    select_policy_from_plane=tc.select_policy_from_plane,\n",
    "    use_wdl=tc.use_wdl, use_plys_to_end=tc.use_plys_to_end,\n",
    "    use_mlp_wdl_ply=tc.use_mlp_wdl_ply,\n",
    "    use_transformer_heads=False, #True,\n",
    "    se_type=None, #'eca_se'\n",
    "    use_simple_transformer_blocks=False, #True\n",
    "    ) # -> 19 pool blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = AlphaZeroResnet(nb_input_channels=input_shape[0], board_height=input_shape[1], board_width=input_shape[2],\n",
    "                channels=256, act_type='relu', num_res_blocks=19,\n",
    "                channels_value_head=8, value_fc_size=256,\n",
    "                channels_policy_head=NB_POLICY_MAP_CHANNELS,\n",
    "                select_policy_from_plane=tc.select_policy_from_plane,\n",
    "                n_labels=NB_LABELS,\n",
    "                use_wdl=tc.use_wdl, use_plys_to_end=tc.use_plys_to_end, use_mlp_wdl_ply=tc.use_mlp_wdl_ply,\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = VisionTransformer(get_b8_config(), img_size=8, in_channels=input_shape[0], num_classes=NB_POLICY_MAP_CHANNELS*64,\n",
    "                          use_wdl=tc.use_wdl, use_plys_to_end=tc.use_plys_to_end, use_mlp_wdl_ply=tc.use_mlp_wdl_ply,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert MXNet Symbol to Gluon Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if tc.framework == 'gluon' and symbol is not None:\n",
    "    inputs = mx.sym.var('data', dtype='float32')\n",
    "    value_out = symbol.get_internals()[main_config['value_output']+'_output']\n",
    "    policy_out = symbol.get_internals()[main_config['policy_output']+'_output']\n",
    "    sym = mx.symbol.Group([value_out, policy_out])\n",
    "    net = mx.gluon.SymbolBlock(sym, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RiseV3(\n",
      "  (body_spatial): Sequential(\n",
      "    (0): _Stem(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(34, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224, bias=False)\n",
      "        (4): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (2): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (3): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (4): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
      "        (4): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (5): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352, bias=False)\n",
      "        (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(352, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (6): _BottlekneckResidualBlock(\n",
      "      (se): _EfficientChannelAttentionModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (body): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): Hardsigmoid()\n",
      "        )\n",
      "      )\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (7): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=416, bias=False)\n",
      "        (4): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(416, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (8): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(352, 352, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=352, bias=False)\n",
      "        (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(352, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (9): _BottlekneckResidualBlock(\n",
      "      (se): _EfficientChannelAttentionModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (body): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): Hardsigmoid()\n",
      "        )\n",
      "      )\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (4): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(480, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (10): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (11): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(544, 544, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=544, bias=False)\n",
      "        (4): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(544, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (12): _BottlekneckResidualBlock(\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(416, 416, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=416, bias=False)\n",
      "        (4): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(416, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (13): _BottlekneckResidualBlock(\n",
      "      (se): _EfficientChannelAttentionModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (body): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): Hardsigmoid()\n",
      "        )\n",
      "      )\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(416, 416, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=416, bias=False)\n",
      "        (4): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(416, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (14): _BottlekneckResidualBlock(\n",
      "      (se): _EfficientChannelAttentionModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (body): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): Hardsigmoid()\n",
      "        )\n",
      "      )\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(448, 448, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=448, bias=False)\n",
      "        (4): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "    (15): _BottlekneckResidualBlock(\n",
      "      (se): _EfficientChannelAttentionModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (body): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): Hardsigmoid()\n",
      "        )\n",
      "      )\n",
      "      (body): Sequential(\n",
      "        (0): Conv2d(256, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (4): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(672, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (path_dropout): DropPath(drop_prob=0.000)\n",
      "    )\n",
      "  )\n",
      "  (value_head): _ValueHead(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (body_wdl): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=3, bias=True)\n",
      "    )\n",
      "    (body_plys): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (body_final): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (policy_head): _PolicyHead(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if tc.framework == 'gluon':\n",
    "    print(net)\n",
    "elif tc.framework == 'pytorch':\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if tc.framework != 'pytorch' and symbol is not None:\n",
    "    display(mx.viz.plot_network(\n",
    "        symbol,\n",
    "        shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "        node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"}\n",
    "    ))\n",
    "elif tc.framework == 'gluon':\n",
    "    display(mx.viz.plot_network(\n",
    "        net(mx.sym.var('data'))[1],\n",
    "        shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "        node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 256, 8, 8]          78,336\n",
      "       BatchNorm2d-2            [-1, 256, 8, 8]             512\n",
      "              ReLU-3            [-1, 256, 8, 8]               0\n",
      "             _Stem-4            [-1, 256, 8, 8]               0\n",
      "            Conv2d-5            [-1, 224, 8, 8]          57,344\n",
      "       BatchNorm2d-6            [-1, 224, 8, 8]             448\n",
      "              ReLU-7            [-1, 224, 8, 8]               0\n",
      "            Conv2d-8            [-1, 224, 8, 8]           2,016\n",
      "       BatchNorm2d-9            [-1, 224, 8, 8]             448\n",
      "             ReLU-10            [-1, 224, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          57,344\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "         DropPath-13            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-14            [-1, 256, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "             ReLU-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 256, 8, 8]           2,304\n",
      "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
      "             ReLU-20            [-1, 256, 8, 8]               0\n",
      "           Conv2d-21            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
      "         DropPath-23            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-24            [-1, 256, 8, 8]               0\n",
      "           Conv2d-25            [-1, 288, 8, 8]          73,728\n",
      "      BatchNorm2d-26            [-1, 288, 8, 8]             576\n",
      "             ReLU-27            [-1, 288, 8, 8]               0\n",
      "           Conv2d-28            [-1, 288, 8, 8]           2,592\n",
      "      BatchNorm2d-29            [-1, 288, 8, 8]             576\n",
      "             ReLU-30            [-1, 288, 8, 8]               0\n",
      "           Conv2d-31            [-1, 256, 8, 8]          73,728\n",
      "      BatchNorm2d-32            [-1, 256, 8, 8]             512\n",
      "         DropPath-33            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-34            [-1, 256, 8, 8]               0\n",
      "           Conv2d-35            [-1, 320, 8, 8]          81,920\n",
      "      BatchNorm2d-36            [-1, 320, 8, 8]             640\n",
      "             ReLU-37            [-1, 320, 8, 8]               0\n",
      "           Conv2d-38            [-1, 320, 8, 8]           2,880\n",
      "      BatchNorm2d-39            [-1, 320, 8, 8]             640\n",
      "             ReLU-40            [-1, 320, 8, 8]               0\n",
      "           Conv2d-41            [-1, 256, 8, 8]          81,920\n",
      "      BatchNorm2d-42            [-1, 256, 8, 8]             512\n",
      "         DropPath-43            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-44            [-1, 256, 8, 8]               0\n",
      "           Conv2d-45            [-1, 352, 8, 8]          90,112\n",
      "      BatchNorm2d-46            [-1, 352, 8, 8]             704\n",
      "             ReLU-47            [-1, 352, 8, 8]               0\n",
      "           Conv2d-48            [-1, 352, 8, 8]           3,168\n",
      "      BatchNorm2d-49            [-1, 352, 8, 8]             704\n",
      "             ReLU-50            [-1, 352, 8, 8]               0\n",
      "           Conv2d-51            [-1, 256, 8, 8]          90,112\n",
      "      BatchNorm2d-52            [-1, 256, 8, 8]             512\n",
      "         DropPath-53            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-54            [-1, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-55            [-1, 256, 1, 1]               0\n",
      "           Conv1d-56               [-1, 256, 1]         327,936\n",
      "      Hardsigmoid-57               [-1, 256, 1]               0\n",
      "_EfficientChannelAttentionModule-58            [-1, 256, 8, 8]               0\n",
      "           Conv2d-59            [-1, 384, 8, 8]          98,304\n",
      "      BatchNorm2d-60            [-1, 384, 8, 8]             768\n",
      "             ReLU-61            [-1, 384, 8, 8]               0\n",
      "           Conv2d-62            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-63            [-1, 384, 8, 8]             768\n",
      "             ReLU-64            [-1, 384, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]          98,304\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "         DropPath-67            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-68            [-1, 256, 8, 8]               0\n",
      "           Conv2d-69            [-1, 416, 8, 8]         106,496\n",
      "      BatchNorm2d-70            [-1, 416, 8, 8]             832\n",
      "             ReLU-71            [-1, 416, 8, 8]               0\n",
      "           Conv2d-72            [-1, 416, 8, 8]           3,744\n",
      "      BatchNorm2d-73            [-1, 416, 8, 8]             832\n",
      "             ReLU-74            [-1, 416, 8, 8]               0\n",
      "           Conv2d-75            [-1, 256, 8, 8]         106,496\n",
      "      BatchNorm2d-76            [-1, 256, 8, 8]             512\n",
      "         DropPath-77            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-78            [-1, 256, 8, 8]               0\n",
      "           Conv2d-79            [-1, 352, 8, 8]          90,112\n",
      "      BatchNorm2d-80            [-1, 352, 8, 8]             704\n",
      "             ReLU-81            [-1, 352, 8, 8]               0\n",
      "           Conv2d-82            [-1, 352, 8, 8]           8,800\n",
      "      BatchNorm2d-83            [-1, 352, 8, 8]             704\n",
      "             ReLU-84            [-1, 352, 8, 8]               0\n",
      "           Conv2d-85            [-1, 256, 8, 8]          90,112\n",
      "      BatchNorm2d-86            [-1, 256, 8, 8]             512\n",
      "         DropPath-87            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-88            [-1, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-89            [-1, 256, 1, 1]               0\n",
      "           Conv1d-90               [-1, 256, 1]         327,936\n",
      "      Hardsigmoid-91               [-1, 256, 1]               0\n",
      "_EfficientChannelAttentionModule-92            [-1, 256, 8, 8]               0\n",
      "           Conv2d-93            [-1, 480, 8, 8]         122,880\n",
      "      BatchNorm2d-94            [-1, 480, 8, 8]             960\n",
      "             ReLU-95            [-1, 480, 8, 8]               0\n",
      "           Conv2d-96            [-1, 480, 8, 8]           4,320\n",
      "      BatchNorm2d-97            [-1, 480, 8, 8]             960\n",
      "             ReLU-98            [-1, 480, 8, 8]               0\n",
      "           Conv2d-99            [-1, 256, 8, 8]         122,880\n",
      "     BatchNorm2d-100            [-1, 256, 8, 8]             512\n",
      "        DropPath-101            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-102            [-1, 256, 8, 8]               0\n",
      "          Conv2d-103            [-1, 512, 8, 8]         131,072\n",
      "     BatchNorm2d-104            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-105            [-1, 512, 8, 8]               0\n",
      "          Conv2d-106            [-1, 512, 8, 8]           4,608\n",
      "     BatchNorm2d-107            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-108            [-1, 512, 8, 8]               0\n",
      "          Conv2d-109            [-1, 256, 8, 8]         131,072\n",
      "     BatchNorm2d-110            [-1, 256, 8, 8]             512\n",
      "        DropPath-111            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-112            [-1, 256, 8, 8]               0\n",
      "          Conv2d-113            [-1, 544, 8, 8]         139,264\n",
      "     BatchNorm2d-114            [-1, 544, 8, 8]           1,088\n",
      "            ReLU-115            [-1, 544, 8, 8]               0\n",
      "          Conv2d-116            [-1, 544, 8, 8]           4,896\n",
      "     BatchNorm2d-117            [-1, 544, 8, 8]           1,088\n",
      "            ReLU-118            [-1, 544, 8, 8]               0\n",
      "          Conv2d-119            [-1, 256, 8, 8]         139,264\n",
      "     BatchNorm2d-120            [-1, 256, 8, 8]             512\n",
      "        DropPath-121            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-122            [-1, 256, 8, 8]               0\n",
      "          Conv2d-123            [-1, 416, 8, 8]         106,496\n",
      "     BatchNorm2d-124            [-1, 416, 8, 8]             832\n",
      "            ReLU-125            [-1, 416, 8, 8]               0\n",
      "          Conv2d-126            [-1, 416, 8, 8]          10,400\n",
      "     BatchNorm2d-127            [-1, 416, 8, 8]             832\n",
      "            ReLU-128            [-1, 416, 8, 8]               0\n",
      "          Conv2d-129            [-1, 256, 8, 8]         106,496\n",
      "     BatchNorm2d-130            [-1, 256, 8, 8]             512\n",
      "        DropPath-131            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-132            [-1, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-133            [-1, 256, 1, 1]               0\n",
      "          Conv1d-134               [-1, 256, 1]         327,936\n",
      "     Hardsigmoid-135               [-1, 256, 1]               0\n",
      "_EfficientChannelAttentionModule-136            [-1, 256, 8, 8]               0\n",
      "          Conv2d-137            [-1, 416, 8, 8]         106,496\n",
      "     BatchNorm2d-138            [-1, 416, 8, 8]             832\n",
      "            ReLU-139            [-1, 416, 8, 8]               0\n",
      "          Conv2d-140            [-1, 416, 8, 8]          10,400\n",
      "     BatchNorm2d-141            [-1, 416, 8, 8]             832\n",
      "            ReLU-142            [-1, 416, 8, 8]               0\n",
      "          Conv2d-143            [-1, 256, 8, 8]         106,496\n",
      "     BatchNorm2d-144            [-1, 256, 8, 8]             512\n",
      "        DropPath-145            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-146            [-1, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-147            [-1, 256, 1, 1]               0\n",
      "          Conv1d-148               [-1, 256, 1]         327,936\n",
      "     Hardsigmoid-149               [-1, 256, 1]               0\n",
      "_EfficientChannelAttentionModule-150            [-1, 256, 8, 8]               0\n",
      "          Conv2d-151            [-1, 448, 8, 8]         114,688\n",
      "     BatchNorm2d-152            [-1, 448, 8, 8]             896\n",
      "            ReLU-153            [-1, 448, 8, 8]               0\n",
      "          Conv2d-154            [-1, 448, 8, 8]          11,200\n",
      "     BatchNorm2d-155            [-1, 448, 8, 8]             896\n",
      "            ReLU-156            [-1, 448, 8, 8]               0\n",
      "          Conv2d-157            [-1, 256, 8, 8]         114,688\n",
      "     BatchNorm2d-158            [-1, 256, 8, 8]             512\n",
      "        DropPath-159            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-160            [-1, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-161            [-1, 256, 1, 1]               0\n",
      "          Conv1d-162               [-1, 256, 1]         327,936\n",
      "     Hardsigmoid-163               [-1, 256, 1]               0\n",
      "_EfficientChannelAttentionModule-164            [-1, 256, 8, 8]               0\n",
      "          Conv2d-165            [-1, 672, 8, 8]         172,032\n",
      "     BatchNorm2d-166            [-1, 672, 8, 8]           1,344\n",
      "            ReLU-167            [-1, 672, 8, 8]               0\n",
      "          Conv2d-168            [-1, 672, 8, 8]           6,048\n",
      "     BatchNorm2d-169            [-1, 672, 8, 8]           1,344\n",
      "            ReLU-170            [-1, 672, 8, 8]               0\n",
      "          Conv2d-171            [-1, 256, 8, 8]         172,032\n",
      "     BatchNorm2d-172            [-1, 256, 8, 8]             512\n",
      "        DropPath-173            [-1, 256, 8, 8]               0\n",
      "_BottlekneckResidualBlock-174            [-1, 256, 8, 8]               0\n",
      "          Conv2d-175              [-1, 8, 8, 8]           2,048\n",
      "     BatchNorm2d-176              [-1, 8, 8, 8]              16\n",
      "            ReLU-177              [-1, 8, 8, 8]               0\n",
      "          Linear-178                    [-1, 3]           1,539\n",
      "          Linear-179                    [-1, 1]             513\n",
      "         Sigmoid-180                    [-1, 1]               0\n",
      "      _ValueHead-181  [[-1, 1], [-1, 3], [-1, 1]]               0\n",
      "          Conv2d-182            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-183            [-1, 256, 8, 8]             512\n",
      "            ReLU-184            [-1, 256, 8, 8]               0\n",
      "          Conv2d-185             [-1, 81, 8, 8]         186,624\n",
      "     _PolicyHead-186                 [-1, 5184]               0\n",
      "================================================================\n",
      "Total params: 5,725,396\n",
      "Trainable params: 5,725,396\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 26.93\n",
      "Params size (MB): 21.84\n",
      "Estimated Total Size (MB): 48.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if tc.framework == 'mxnet':\n",
    "    mx.viz.print_summary(\n",
    "        symbol,\n",
    "        shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "    )\n",
    "elif tc.framework == 'gluon':\n",
    "    mx.viz.print_summary(\n",
    "    net(mx.sym.var('data'))[1], \n",
    "    shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "    ) \n",
    "elif tc.framework == 'pytorch':\n",
    "    summary(model, (input_shape[0], input_shape[1], input_shape[2]), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m Unsupported operator aten::add_ encountered 48 time(s)\n",
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m Unsupported operator aten::add encountered 16 time(s)\n",
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m Unsupported operator aten::hardsigmoid encountered 5 time(s)\n",
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m Unsupported operator aten::expand_as encountered 5 time(s)\n",
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m Unsupported operator aten::mul encountered 5 time(s)\n",
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m Unsupported operator aten::sigmoid encountered 1 time(s)\n",
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m Unsupported operator aten::softmax encountered 1 time(s)\n",
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m Unsupported operator aten::neg encountered 1 time(s)\n",
      "2023-07-17 18:06:23 fvcore.nn.jit_analysis[12628] \u001b[1mWARNING\u001b[0m The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "body_spatial.1.path_dropout, body_spatial.10.path_dropout, body_spatial.11.path_dropout, body_spatial.12.path_dropout, body_spatial.13.path_dropout, body_spatial.14.path_dropout, body_spatial.15.path_dropout, body_spatial.2.path_dropout, body_spatial.3.path_dropout, body_spatial.4.path_dropout, body_spatial.5.path_dropout, body_spatial.6.path_dropout, body_spatial.7.path_dropout, body_spatial.8.path_dropout, body_spatial.9.path_dropout, value_head.body_final, value_head.body_final.0, value_head.body_final.1, value_head.body_final.2, value_head.body_final.3\n",
      "266248704\n",
      "| module                           | #parameters or shape   | #flops     |\n",
      "|:---------------------------------|:-----------------------|:-----------|\n",
      "| model                            | 5.857M                 | 0.266G     |\n",
      "|  body_spatial                    |  4.944M                |  0.216G    |\n",
      "|   body_spatial.0.body            |   78.848K              |   5.095M   |\n",
      "|    body_spatial.0.body.0         |    78.336K             |    5.014M  |\n",
      "|    body_spatial.0.body.1         |    0.512K              |    81.92K  |\n",
      "|   body_spatial.1.body            |   0.118M               |   7.694M   |\n",
      "|    body_spatial.1.body.0         |    57.344K             |    3.67M   |\n",
      "|    body_spatial.1.body.1         |    0.448K              |    71.68K  |\n",
      "|    body_spatial.1.body.3         |    2.016K              |    0.129M  |\n",
      "|    body_spatial.1.body.4         |    0.448K              |    71.68K  |\n",
      "|    body_spatial.1.body.6         |    57.344K             |    3.67M   |\n",
      "|    body_spatial.1.body.7         |    0.512K              |    81.92K  |\n",
      "|   body_spatial.2.body            |   0.135M               |   8.782M   |\n",
      "|    body_spatial.2.body.0         |    65.536K             |    4.194M  |\n",
      "|    body_spatial.2.body.1         |    0.512K              |    81.92K  |\n",
      "|    body_spatial.2.body.3         |    2.304K              |    0.147M  |\n",
      "|    body_spatial.2.body.4         |    0.512K              |    81.92K  |\n",
      "|    body_spatial.2.body.6         |    65.536K             |    4.194M  |\n",
      "|    body_spatial.2.body.7         |    0.512K              |    81.92K  |\n",
      "|   body_spatial.3.body            |   0.152M               |   9.869M   |\n",
      "|    body_spatial.3.body.0         |    73.728K             |    4.719M  |\n",
      "|    body_spatial.3.body.1         |    0.576K              |    92.16K  |\n",
      "|    body_spatial.3.body.3         |    2.592K              |    0.166M  |\n",
      "|    body_spatial.3.body.4         |    0.576K              |    92.16K  |\n",
      "|    body_spatial.3.body.6         |    73.728K             |    4.719M  |\n",
      "|    body_spatial.3.body.7         |    0.512K              |    81.92K  |\n",
      "|   body_spatial.4.body            |   0.169M               |   10.957M  |\n",
      "|    body_spatial.4.body.0         |    81.92K              |    5.243M  |\n",
      "|    body_spatial.4.body.1         |    0.64K               |    0.102M  |\n",
      "|    body_spatial.4.body.3         |    2.88K               |    0.184M  |\n",
      "|    body_spatial.4.body.4         |    0.64K               |    0.102M  |\n",
      "|    body_spatial.4.body.6         |    81.92K              |    5.243M  |\n",
      "|    body_spatial.4.body.7         |    0.512K              |    81.92K  |\n",
      "|   body_spatial.5.body            |   0.185M               |   12.044M  |\n",
      "|    body_spatial.5.body.0         |    90.112K             |    5.767M  |\n",
      "|    body_spatial.5.body.1         |    0.704K              |    0.113M  |\n",
      "|    body_spatial.5.body.3         |    3.168K              |    0.203M  |\n",
      "|    body_spatial.5.body.4         |    0.704K              |    0.113M  |\n",
      "|    body_spatial.5.body.6         |    90.112K             |    5.767M  |\n",
      "|    body_spatial.5.body.7         |    0.512K              |    81.92K  |\n",
      "|   body_spatial.6                 |   0.53M                |   13.476M  |\n",
      "|    body_spatial.6.se             |    0.328M              |    0.344M  |\n",
      "|    body_spatial.6.body           |    0.202M              |    13.132M |\n",
      "|   body_spatial.7.body            |   0.219M               |   14.219M  |\n",
      "|    body_spatial.7.body.0         |    0.106M              |    6.816M  |\n",
      "|    body_spatial.7.body.1         |    0.832K              |    0.133M  |\n",
      "|    body_spatial.7.body.3         |    3.744K              |    0.24M   |\n",
      "|    body_spatial.7.body.4         |    0.832K              |    0.133M  |\n",
      "|    body_spatial.7.body.6         |    0.106M              |    6.816M  |\n",
      "|    body_spatial.7.body.7         |    0.512K              |    81.92K  |\n",
      "|   body_spatial.8.body            |   0.191M               |   12.405M  |\n",
      "|    body_spatial.8.body.0         |    90.112K             |    5.767M  |\n",
      "|    body_spatial.8.body.1         |    0.704K              |    0.113M  |\n",
      "|    body_spatial.8.body.3         |    8.8K                |    0.563M  |\n",
      "|    body_spatial.8.body.4         |    0.704K              |    0.113M  |\n",
      "|    body_spatial.8.body.6         |    90.112K             |    5.767M  |\n",
      "|    body_spatial.8.body.7         |    0.512K              |    81.92K  |\n",
      "|   body_spatial.9                 |   0.58M                |   16.738M  |\n",
      "|    body_spatial.9.se             |    0.328M              |    0.344M  |\n",
      "|    body_spatial.9.body           |    0.253M              |    16.394M |\n",
      "|   body_spatial.10.body           |   0.269M               |   17.482M  |\n",
      "|    body_spatial.10.body.0        |    0.131M              |    8.389M  |\n",
      "|    body_spatial.10.body.1        |    1.024K              |    0.164M  |\n",
      "|    body_spatial.10.body.3        |    4.608K              |    0.295M  |\n",
      "|    body_spatial.10.body.4        |    1.024K              |    0.164M  |\n",
      "|    body_spatial.10.body.6        |    0.131M              |    8.389M  |\n",
      "|    body_spatial.10.body.7        |    0.512K              |    81.92K  |\n",
      "|   body_spatial.11.body           |   0.286M               |   18.569M  |\n",
      "|    body_spatial.11.body.0        |    0.139M              |    8.913M  |\n",
      "|    body_spatial.11.body.1        |    1.088K              |    0.174M  |\n",
      "|    body_spatial.11.body.3        |    4.896K              |    0.313M  |\n",
      "|    body_spatial.11.body.4        |    1.088K              |    0.174M  |\n",
      "|    body_spatial.11.body.6        |    0.139M              |    8.913M  |\n",
      "|    body_spatial.11.body.7        |    0.512K              |    81.92K  |\n",
      "|   body_spatial.12.body           |   0.226M               |   14.645M  |\n",
      "|    body_spatial.12.body.0        |    0.106M              |    6.816M  |\n",
      "|    body_spatial.12.body.1        |    0.832K              |    0.133M  |\n",
      "|    body_spatial.12.body.3        |    10.4K               |    0.666M  |\n",
      "|    body_spatial.12.body.4        |    0.832K              |    0.133M  |\n",
      "|    body_spatial.12.body.6        |    0.106M              |    6.816M  |\n",
      "|    body_spatial.12.body.7        |    0.512K              |    81.92K  |\n",
      "|   body_spatial.13                |   0.554M               |   14.989M  |\n",
      "|    body_spatial.13.se            |    0.328M              |    0.344M  |\n",
      "|    body_spatial.13.body          |    0.226M              |    14.645M |\n",
      "|   body_spatial.14                |   0.571M               |   16.11M   |\n",
      "|    body_spatial.14.se            |    0.328M              |    0.344M  |\n",
      "|    body_spatial.14.body          |    0.243M              |    15.766M |\n",
      "|   body_spatial.15                |   0.681M               |   23.263M  |\n",
      "|    body_spatial.15.se            |    0.328M              |    0.344M  |\n",
      "|    body_spatial.15.body          |    0.353M              |    22.919M |\n",
      "|  value_head                      |  0.136M                |  0.136M    |\n",
      "|   value_head.body                |   2.064K               |   0.134M   |\n",
      "|    value_head.body.0             |    2.048K              |    0.131M  |\n",
      "|    value_head.body.1             |    16                  |    2.56K   |\n",
      "|   value_head.body_wdl.0          |   1.539K               |   1.536K   |\n",
      "|    value_head.body_wdl.0.weight  |    (3, 512)            |            |\n",
      "|    value_head.body_wdl.0.bias    |    (3,)                |            |\n",
      "|   value_head.body_plys.0         |   0.513K               |   0.512K   |\n",
      "|    value_head.body_plys.0.weight |    (1, 512)            |            |\n",
      "|    value_head.body_plys.0.bias   |    (1,)                |            |\n",
      "|   value_head.body_final          |   0.132M               |            |\n",
      "|    value_head.body_final.0       |    0.131M              |            |\n",
      "|    value_head.body_final.2       |    0.257K              |            |\n",
      "|  policy_head.body                |  0.777M                |  49.775M   |\n",
      "|   policy_head.body.0             |   0.59M                |   37.749M  |\n",
      "|    policy_head.body.0.weight     |    (256, 256, 3, 3)    |            |\n",
      "|   policy_head.body.1             |   0.512K               |   81.92K   |\n",
      "|    policy_head.body.1.weight     |    (256,)              |            |\n",
      "|    policy_head.body.1.bias       |    (256,)              |            |\n",
      "|   policy_head.body.3             |   0.187M               |   11.944M  |\n",
      "|    policy_head.body.3.weight     |    (81, 256, 3, 3)     |            |\n"
     ]
    }
   ],
   "source": [
    "if tc.framework == 'pytorch':\n",
    "    dummy_input = torch.Tensor(np.expand_dims(x_val[0], axis=0)).to('cpu')\n",
    "    flops = FlopCountAnalysis(model, dummy_input)\n",
    "    print(flops.total())\n",
    "    from fvcore.nn import flop_count_table\n",
    "    print(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the weights \n",
    "(only needed if no pretrained weights are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if tc.framework == 'mxnet':\n",
    "    # create a trainable module on compute context\n",
    "    if tc.use_wdl and tc.use_plys_to_end:\n",
    "        label_names=['value_label', 'policy_label', 'wdl_label', 'plys_to_end_label']\n",
    "    else:\n",
    "        label_names=['value_label', 'policy_label']\n",
    "    \n",
    "    model = mx.mod.Module(symbol=symbol, context=ctx, label_names=label_names)\n",
    "    model.bind(for_training=True, data_shapes=[('data', (tc.batch_size, input_shape[0], input_shape[1], input_shape[2]))],\n",
    "             label_shapes=val_iter.provide_label)\n",
    "    model.init_params(mx.initializer.Xavier(rnd_type='uniform', factor_type='avg', magnitude=2.24))\n",
    "    if tc.params_file:\n",
    "        model.load_params(tc.export_dir + \"weights/\" + tc.params_file)\n",
    "elif tc.framework == 'gluon':    \n",
    "    # Initializing the parameters\n",
    "    for param in net.collect_params('.*gamma|.*moving_mean|.*moving_var'):\n",
    "        net.params[param].initialize(mx.initializer.Constant(1), ctx=ctx)\n",
    "    for param in net.collect_params('.*beta|.*bias'):\n",
    "        net.params[param].initialize(mx.initializer.Constant(0), ctx=ctx)\n",
    "    for param in net.collect_params('.*weight'):\n",
    "        net.params[param].initialize(mx.init.Xavier(rnd_type='uniform', factor_type='avg', magnitude=2.24), ctx=ctx)\n",
    "\n",
    "    if tc.params_file:\n",
    "        net.collect_params().load(tc.export_dir + \"weights/\" + tc.params_file, ctx)\n",
    "    net.hybridize()\n",
    "elif tc.framework == 'pytorch':\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                m.bias.data.fill_(0.01)\n",
    "    #model.apply(init_weights)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda(torch.device(f\"cuda:{tc.device_id}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to.metrics = get_metrics(tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a training agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if tc.framework == 'mxnet':\n",
    "    train_agent = TrainerAgentMXNET(model, symbol, val_iter, tc, to, use_rtpt=True)\n",
    "elif tc.framework == 'gluon':\n",
    "    train_agent = TrainerAgentGluon(net, val_data, tc, to, use_rtpt=True)\n",
    "elif tc.framework == 'pytorch':\n",
    "    train_agent = TrainerAgentPytorch(model, val_data, tc, to, use_rtpt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if tc.framework == 'mxnet':\n",
    "    print(model.score(val_iter, to.metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 18:06:24 root[12628] \u001b[1mINFO\u001b[0m EPOCH 1\n",
      "2023-07-17 18:06:24 root[12628] \u001b[1mINFO\u001b[0m =========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a45a747e34046d6b5dbc5f383c14415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 6.00 GiB total capacity; 5.17 GiB already allocated; 0 bytes free; 5.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m (k_steps_final, value_loss_final, policy_loss_final, value_acc_sign_final, val_p_acc_final), \\\n\u001b[1;32m----> 2\u001b[0m     (k_steps_best, val_metric_values_best) \u001b[39m=\u001b[39m train_agent\u001b[39m.\u001b[39;49mtrain(cur_it)\n",
      "File \u001b[1;32md:\\Jinyao\\Masterarbeit\\CrazyAra\\DeepCrazyhouse\\src\\training\\../../..\\DeepCrazyhouse\\src\\training\\trainer_agent_pytorch.py:124\u001b[0m, in \u001b[0;36mTrainerAgentPytorch.train\u001b[1;34m(self, cur_it)\u001b[0m\n\u001b[0;32m    121\u001b[0m train_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_train_loader(part_id)\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m _, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m--> 124\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_update(batch)\n\u001b[0;32m    126\u001b[0m     \u001b[39m# add the graph representation of the network to the tensorboard log file\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_exported \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtc\u001b[39m.\u001b[39mlog_metrics_to_tensorboard:\n",
      "File \u001b[1;32md:\\Jinyao\\Masterarbeit\\CrazyAra\\DeepCrazyhouse\\src\\training\\../../..\\DeepCrazyhouse\\src\\training\\trainer_agent_pytorch.py:329\u001b[0m, in \u001b[0;36mTrainerAgentPytorch.train_update\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mold_label \u001b[39m=\u001b[39m value_label\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtc\u001b[39m.\u001b[39muse_wdl \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtc\u001b[39m.\u001b[39muse_plys_to_end:\n\u001b[1;32m--> 329\u001b[0m     value_out, policy_out, _, wdl_out, plys_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model(data)\n\u001b[0;32m    330\u001b[0m     wdl_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwdl_loss(wdl_out, wdl_label)\n\u001b[0;32m    331\u001b[0m     ply_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mply_loss(torch\u001b[39m.\u001b[39mflatten(plys_out), plys_label)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Jinyao\\Masterarbeit\\CrazyAra\\DeepCrazyhouse\\src\\training\\../../..\\DeepCrazyhouse\\src\\domain\\neural_net\\architectures\\pytorch\\rise_mobile_v3.py:171\u001b[0m, in \u001b[0;36mRiseV3.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m    Implementation of the forward pass of the full network\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m    Uses a broadcast add operation for the shortcut and the output of the residual block\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39m    :param x: Input to the ResidualBlock\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m    :return: Value & Policy Output\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbody_spatial(x)\n\u001b[0;32m    173\u001b[0m     \u001b[39mreturn\u001b[39;00m process_value_policy_head(out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_head, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_head, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_plys_to_end, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_wdl)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Jinyao\\Masterarbeit\\CrazyAra\\DeepCrazyhouse\\src\\training\\../../..\\DeepCrazyhouse\\src\\domain\\neural_net\\architectures\\pytorch\\builder_util.py:475\u001b[0m, in \u001b[0;36m_BottlekneckResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mse_type:\n\u001b[0;32m    474\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mse(x)\n\u001b[1;32m--> 475\u001b[0m \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_dropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbody(x))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    177\u001b[0m     bn_training,\n\u001b[0;32m    178\u001b[0m     exponential_average_factor,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    180\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2436\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2438\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2439\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2440\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 6.00 GiB total capacity; 5.17 GiB already allocated; 0 bytes free; 5.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "(k_steps_final, value_loss_final, policy_loss_final, value_acc_sign_final, val_p_acc_final), \\\n",
    "    (k_steps_best, val_metric_values_best) = train_agent.train(cur_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the last model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prefix = tc.export_dir + \"weights/model-%.5f-%.3f\" % (policy_loss_final, val_p_acc_final)\n",
    "\n",
    "if tc.framework == 'mxnet':\n",
    "    # the export function saves both the architecture and the weights\n",
    "    model.save_checkpoint(prefix, epoch=k_steps_final)\n",
    "elif tc.framework == 'gluon':\n",
    "    # the export function saves both the architecture and the weights\n",
    "    net.export(prefix, epoch=k_steps_final)\n",
    "    logging.info(\"Saved checkpoint to %s-%04d.params\", prefix, k_steps_final)\n",
    "elif tc.framework == 'pytorch':\n",
    "    # the export function saves both the architecture and the weights\n",
    "    save_torch_state(model, torch.optim.SGD(model.parameters(), lr=tc.max_lr), '%s-%04d.tar' % (prefix, k_steps_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print validation metrics for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(val_metric_values_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy best model to best-model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_best = val_metric_values_best[\"loss\"]\n",
    "val_p_acc_best = val_metric_values_best[\"policy_acc\"]\n",
    "\n",
    "model_name = \"model-%.5f-%.3f\" % (val_loss_best, val_p_acc_best)\n",
    "model_prefix = tc.export_dir + \"weights/\" + model_name\n",
    "model_arch_path = '%s-symbol.json' % model_prefix\n",
    "model_params_path = '%s-%04d.params' % (model_prefix, k_steps_best)\n",
    "model_tar_path = '%s-%04d.tar' % (model_prefix, k_steps_best)\n",
    "\n",
    "if not os.path.exists(tc.export_dir + \"best-model\"):\n",
    "    os.mkdir(tc.export_dir + \"best-model\")\n",
    "    \n",
    "best_model_prefix = tc.export_dir + \"best-model/\" + model_name\n",
    "best_model_arch_path = '%s-symbol.json' % best_model_prefix\n",
    "best_model_params_path = '%s-%04d.params' % (best_model_prefix, k_steps_best)\n",
    "best_model_tar_path = '%s-%04d.tar' % (best_model_prefix, k_steps_best)\n",
    "\n",
    "if tc.framework == 'mxnet' or tc.framework == 'gluon':\n",
    "    shutil.copy(model_arch_path, best_model_arch_path)\n",
    "    shutil.copy(model_params_path, best_model_params_path)\n",
    "elif tc.framework == 'pytorch':\n",
    "    shutil.copy(model_tar_path, best_model_tar_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best model once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delete the current net object form memory\n",
    "if tc.framework == 'mxnet':\n",
    "    del model\n",
    "elif tc.framework == 'gluon':\n",
    "    del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('load current best model:', model_params_path)\n",
    "\n",
    "if tc.framework == 'mxnet' or tc.framework == 'gluon':\n",
    "    symbol = mx.sym.load(model_arch_path)\n",
    "    inputs = mx.sym.var('data', dtype='float32')\n",
    "    value_out = symbol.get_internals()[main_config['value_output']+'_output']\n",
    "    policy_out = symbol.get_internals()[main_config['policy_output']+'_output']\n",
    "    if tc.use_wdl and tc.use_plys_to_end:\n",
    "        auxiliary_out = symbol.get_internals()[main_config['auxiliary_output']+'_output']\n",
    "        wdl_out = symbol.get_internals()[main_config['wdl_output']+'_output']\n",
    "        ply_to_end_out = symbol.get_internals()[main_config['plys_to_end_output']+'_output']\n",
    "        sym = mx.symbol.Group([value_out, policy_out, auxiliary_out, wdl_out, ply_to_end_out])\n",
    "    else:\n",
    "        sym = mx.symbol.Group([value_out, policy_out])\n",
    "    net = mx.gluon.SymbolBlock(sym, inputs)\n",
    "    net.collect_params().load(model_params_path, ctx)\n",
    "elif tc.framework == 'pytorch':\n",
    "    load_torch_state(model, torch.optim.SGD(model.parameters(), lr=tc.max_lr), model_tar_path, tc.device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('best val_loss: %.5f with v_policy_acc: %.5f at k_steps_best %d' % (val_loss_best, val_p_acc_best, k_steps_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if tc.use_wdl and tc.use_plys_to_end:\n",
    "    outputs = [main_config['value_output']+'_output', main_config['policy_output']+'_output',\n",
    "               main_config['auxiliary_output']+'_output',\n",
    "               main_config['wdl_output']+'_output', main_config['plys_to_end_output']+'_output']\n",
    "else:\n",
    "    outputs = [main_config['value_output']+'_output', main_config['policy_output']+'_output',]\n",
    "\n",
    "if tc.framework == 'mxnet':\n",
    "    convert_mxnet_model_to_onnx(best_model_arch_path, best_model_params_path, \n",
    "                                outputs, \n",
    "                                tuple(input_shape), tuple([1, 8, 16, 64]), True)\n",
    "elif tc.framework == 'pytorch':\n",
    "    model_prefix = \"%s-%04d\" % (model_name, k_steps_best)\n",
    "    with torch.no_grad():\n",
    "        ctx = get_context(tc.context, tc.device_id)\n",
    "        dummy_input = torch.zeros(1, input_shape[0], input_shape[1], input_shape[2]).to(ctx)\n",
    "        export_to_onnx(model, 1,\n",
    "                       dummy_input,\n",
    "                       Path(tc.export_dir) / Path(\"best-model\"), model_prefix, tc.use_wdl and tc.use_plys_to_end,\n",
    "                       True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Saved json, weight & onnx files of the best model to %s\" % (tc.export_dir + \"best-model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show move predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if mode == MODE_CHESS:\n",
    "    start_board = chess.Board()\n",
    "elif mode == MODE_CRAZYHOUSE:\n",
    "    start_board = chess.variant.CrazyhouseBoard()\n",
    "else:\n",
    "    start_board = planes_to_board(x_val[idx], normalized_input=tc.normalize, mode=mode)\n",
    "board = start_board\n",
    "print(chess.COLOR_NAMES[board.turn])\n",
    "if board.uci_variant == \"crazyhouse\":\n",
    "    print(board.pockets)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_single(net, x, select_policy_from_plane=False):\n",
    "    \n",
    "    out = [None, None]\n",
    "    if tc.framework == 'mxnet' or tc.framework == 'gluon':\n",
    "        pred = net(mx.nd.array(np.expand_dims(x, axis=0), ctx=ctx))\n",
    "        out[0] = pred[0].asnumpy()\n",
    "        out[1] = pred[1].softmax().asnumpy()\n",
    "    elif tc.framework == 'pytorch':\n",
    "        with torch.no_grad():\n",
    "            pred = net(torch.Tensor(np.expand_dims(x, axis=0)).to(ctx))\n",
    "            out[0] = pred[0].to(torch.device(\"cpu\")).numpy()\n",
    "            out[1] = pred[1].to(torch.device(\"cpu\")).softmax(dim=1).numpy()\n",
    "    if select_policy_from_plane:\n",
    "        out[1] = out[1][:, FLAT_PLANE_IDX]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tc.framework == 'pytorch':\n",
    "    net = model\n",
    "    net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start_pos = board_to_planes(board, normalize=tc.normalize, mode=mode)\n",
    "pred = predict_single(net, x_start_pos, tc.select_policy_from_plane)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_to_best_move(board, yp_val[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opts = 5\n",
    "selected_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "selected_moves[:opts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.barh(range(opts)[::-1], probs[:opts])\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(opts)[::-1])\n",
    "ax.set_yticklabels(selected_moves[:opts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "board = start_board\n",
    "board.push_uci('e2e4')\n",
    "board.push_uci('e7e5')\n",
    "board.push_uci('f1c4')\n",
    "board.push_uci('b8c6')\n",
    "board.push_uci('d1h5')\n",
    "x_scholar_atck = board_to_planes(board, normalize=tc.normalize, mode=mode)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = predict_single(net, x_scholar_atck, tc.select_policy_from_plane)\n",
    "\n",
    "selected_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "plt.barh(range(opts)[::-1], probs[:opts])\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(opts)[::-1])\n",
    "ax.set_yticklabels(selected_moves[:opts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "board.push(selected_moves[0])\n",
    "board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_idcs_test, x_test, yv_test, yp_test, yplys_test, pgn_datasets_test = load_pgn_dataset(dataset_type='test', part_id=0,\n",
    "                                                                               verbose=True, normalize=True)\n",
    "test_data = get_data_loader(x_test, yv_test, yp_test, yplys_test, tc, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if tc.framework == 'mxnet':\n",
    "    metrics = metrics_gluon\n",
    "\n",
    "evaluate_metrics(to.metrics, test_data, net, nb_batches=None, sparse_policy_label=tc.sparse_policy_label, ctx=ctx,\n",
    "                 apply_select_policy_from_plane=tc.select_policy_from_plane, use_wdl=tc.use_wdl,\n",
    "                 use_plys_to_end=tc.use_plys_to_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show result on mate-in-one problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_idcs_mate, x_mate, yv_mate, yp_mate, yplys_mate, pgn_dataset_mate = load_pgn_dataset(dataset_type='mate_in_one', part_id=0,\n",
    "                                                                              verbose=True, normalize=tc.normalize)\n",
    "yplys_mate = np.ones(len(yv_mate))\n",
    "mate_data = get_data_loader(x_mate, yv_mate, yp_mate, yplys_mate, tc, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mate In One Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_metrics(to.metrics, mate_data, net, nb_batches=None, sparse_policy_label=tc.sparse_policy_label, ctx=ctx,\n",
    "                 apply_select_policy_from_plane=tc.select_policy_from_plane, use_wdl=tc.use_wdl,\n",
    "                 use_plys_to_end=tc.use_plys_to_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some example mate problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_pos(net, x_mate, yp_mate, verbose=False, select_policy_from_plane=False):\n",
    "    \n",
    "    board = planes_to_board(x_mate, normalized_input=tc.normalize, mode=mode)\n",
    "    if verbose is True:\n",
    "        print(\"{0}'s turn\".format(chess.COLOR_NAMES[board.turn]))\n",
    "        if board.uci_variant == \"crazyhouse\":\n",
    "            print(\"black/white {0}\".format(board.pockets))\n",
    "    pred = predict_single(net, x_mate, select_policy_from_plane=select_policy_from_plane)\n",
    "    \n",
    "    true_move = policy_to_move(yp_mate, mirror_policy=board.turn==chess.BLACK)\n",
    "    \n",
    "    opts = 5\n",
    "    pred_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "    pred_moves = pred_moves[:opts]\n",
    "    \n",
    "    legal_move_cnt = board.legal_moves.count()\n",
    "    mate_move_cnt = str(board.legal_moves).count('#')\n",
    "    \n",
    "    is_mate_5_top = False\n",
    "    \n",
    "    for pred_move in pred_moves:\n",
    "        board_5_top = deepcopy(board)\n",
    "        board_5_top.push(pred_move)\n",
    "        if board_5_top.is_checkmate() is True:\n",
    "            is_mate_5_top = True\n",
    "            break\n",
    "    \n",
    "    board.push(pred_moves[0])\n",
    "    \n",
    "    is_checkmate = False\n",
    "    if board.is_checkmate() is True:\n",
    "        is_checkmate = True\n",
    "        \n",
    "    filtered_pred = sorted(pred[1][0], reverse=True)\n",
    "    \n",
    "    if verbose is True:\n",
    "        plt.barh(range(opts)[::-1], filtered_pred[:opts])\n",
    "        ax = plt.gca()\n",
    "        ax.set_yticks(range(opts)[::-1])\n",
    "        ax.set_yticklabels(pred_moves)\n",
    "        plt.title('True Move:' + str(true_move) +\n",
    "                 '\\nEval:' + str(pred[0][0]))\n",
    "        plt.show()\n",
    "    \n",
    "    return pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_pos = len(x_mate)\n",
    "mates_found = []\n",
    "mates_5_top_found = []\n",
    "legal_mv_cnts = []\n",
    "mate_mv_cnts = []\n",
    "\n",
    "for i in range(nb_pos):\n",
    "    pred, pred_moves, true_move, board, is_mate, is_mate_5_top, legal_mv_cnt, mate_mv_cnt= eval_pos(net, x_mate[i], yp_mate[i], select_policy_from_plane=tc.select_policy_from_plane)\n",
    "    mates_found.append(is_mate)\n",
    "    legal_mv_cnts.append(legal_mv_cnt)\n",
    "    mate_mv_cnts.append(mate_mv_cnt)\n",
    "    mates_5_top_found.append(is_mate_5_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(mate_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(legal_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Guessing Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(mate_mv_cnts).mean() / np.array(legal_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciton Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('mate_in_one_acc:', sum(mates_found) / nb_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(mates_5_top_found) / nb_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pgn_dataset_mate.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata = np.array(pgn_dataset_mate['metadata'])\n",
    "metadata[0, :]\n",
    "metadata[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site_mate = metadata[1:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_string(np_string):\n",
    "    string = str(site_mate[i]).replace(\"b'\", \"\")\n",
    "    string = string.replace(\"'\", \"\")\n",
    "    string = string.replace('\"', '')\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import chess.svg\n",
    "from IPython.display import SVG, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the result of the first 17 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(17):\n",
    "    print(clean_string(site_mate[i]))\n",
    "    pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=True, select_policy_from_plane=tc.select_policy_from_plane)\n",
    "    pred_move = pred_moves[0]\n",
    "    pred_arrow = chess.svg.Arrow(pred_move.from_square, pred_move.to_square)\n",
    "    SVG(data=chess.svg.board(board=board, arrows=[pred_arrow], size=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show examples where it failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mate_missed = 0\n",
    "for i in range(1000):\n",
    "    pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=False, select_policy_from_plane=tc.select_policy_from_plane)\n",
    "    if is_mate_5_top is False:\n",
    "        mate_missed += 1\n",
    "        print(clean_string(site_mate[i]))\n",
    "        pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=True, select_policy_from_plane=tc.select_policy_from_plane)\n",
    "        pred_move = pred_moves[0]\n",
    "        pred_arrow = chess.svg.Arrow(pred_move.from_square, pred_move.to_square)\n",
    "        SVG(data=chess.svg.board(board=board, arrows=[pred_arrow], size=400))\n",
    "    if mate_missed == 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
